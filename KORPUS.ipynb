{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehmetKay-sudo/Data_Science/blob/main/KORPUS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mein Endergebnis \n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for file in files: # Loop through each file in the list of files\n",
        "    if file.endswith('.xlsx'): # Check if the file ends with .xlsx\n",
        "        xlsx = pd.ExcelFile(path + file) # Read in the excel file using pandas\n",
        "        file_name_we, file_extension = os.path.splitext(file) # Split the file name and extension\n",
        "\n",
        "        for sheet in xlsx.sheet_names: # Loop through each sheet in the excel file\n",
        "            if \"char stats\" in sheet_name: # check if \"char stats\" exists in the name\n",
        "                continue\n",
        "            df = xlsx.parse(sheet) # Read in the data from the current sheet\n",
        "            sheet_name = sheet # Store the sheet name\n",
        "            df = df.rename(columns=lambda x: x.replace(',',''))\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('#', '-')\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('^', 'ø', regex=False)\n",
        "            \n",
        "            for x, row in df.iterrows():\n",
        "                if row['SEGMENTC30'].startswith('~'):\n",
        "                    cell_above = df.at[x - 1, 'SEGMENTC30']\n",
        "                    cell_above = cell_above.strip()\n",
        "                    last_char = cell_above[-2]\n",
        "                    df.at[x, 'SEGMENTC30'] = row['SEGMENTC30'].replace('~', '〈〈' + last_char + '〉〉') \n",
        "                    \n",
        "            json_list = [] \n",
        "            \n",
        "            for reference_value, group in df.groupby('REFERENCEC8'): # Group the data in the dataframe by the \"REFERENCEC8\" column\n",
        "                group_df = group.reset_index(drop=False) # Reset the index for the group\n",
        "                json_dict = {} # Initialize the dictionary to store the contents of the JSON file\n",
        "                json_dict['eClass'] = \"http://btsCorpusModel/1.0#//BTSSenctence\" \n",
        "                json_dict['_id'] = 'FUNK-' + file_name_we + '-' + sheet_name + '-' + str(reference_value)\n",
        "                json_dict['state'] = 'active'\n",
        "                json_dict['sentenceItems'] = []\n",
        "                json_dict['sentenceItems'].append({'eClass': \"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                  '_id': 'FUNK-' + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-PARA-01\",\n",
        "                                  'type': 'para',\n",
        "                                  'name': str(reference_value)[-4:-2] + '-' + str(reference_value)[-2:], \n",
        "                                  'state': 'active',})\n",
        "                \n",
        "                \n",
        "                counter = 1\n",
        "                def add_sentence_item(row): # takes a row from the dataframe and adds a new sentence item to the json_dict\n",
        "                    global counter\n",
        "                    json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(counter),\n",
        "                                \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                 \"flexCode\": str(row[\"SEGMENTC30\"])})\n",
        "                    if str(row[\"SEGMENTC30\"]).endswith(\"·\"):\n",
        "                        json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(counter),\n",
        "                                \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                 \"flexCode\": str(row[\"SEGMENTC30\"][:-1])})\n",
        "                        json_dict['sentenceItems'].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                            \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + str(row[\"NO_LIGNEN60\"])+ \"-\" + str(counter)+ \"-INTP-01\",\n",
        "                                            \"type\": \"MiddleDot\",\n",
        "                                            \"state\": \"active\",\n",
        "                                            \"wChar\":\"·\"})    \n",
        "                        \n",
        "                    counter += 1\n",
        "                    \n",
        "                group_df.apply(add_sentence_item, axis=1) # Apply the add_sentence_item function to each row in the dataframe, called once per row(axis=1)\n",
        "        \n",
        "                \n",
        "                json_list.append(json_dict) # adds current json_dict to the json_list\n",
        "                file_path = os.path.join(path, file_name_we + '_' + sheet_name + '.json') # creating file path and name\n",
        "                with open(file_path, 'w', encoding='utf-8') as f: # opening the file with UTF-8 encoding\n",
        "                    json.dump(json_list, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "z2Ug3_FUuVv8",
        "outputId": "5212983c-3d74-422f-e299-4dfa2bd284c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8b9d283c895e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Loop through each file in the list of files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimized code\n",
        "#libraries\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#path - needs to be specified, if used on a different machine\n",
        "path = 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\n",
        "#path put in a variable named files\n",
        "files = os.listdir(path)\n",
        "\n",
        "\n",
        "def corploop():\n",
        "  for file in files: # Loop through each file in the list of files\n",
        "       if file.endswith('.xlsx'): # Check if the file ends with .xlsx\n",
        "       xlsx = pd.ExcelFile(path + file) # Read in the excel file using pandas\n",
        "       file_name_we, file_extension = os.path.splitext(file) # Split the file name and extension\n",
        "       \n",
        "       for sheet in xlsx.sheet_names: # Loop through each sheet in the excel file\n",
        "           if \"char stats\" in sheet_name: # check if \"char stats\" exists in the name\n",
        "           continue\n",
        "               df = xlsx.parse(sheet) # Read in the data from the current sheet\n",
        "               sheet_name = sheet # Store the sheet name\n",
        "               df = df.rename(columns=lambda x: x.replace(',',''))\n",
        "               df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('#', '-')\n",
        "               df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('^', 'ø', regex=False)\n",
        "               \n",
        "               \n",
        "               for x, row in df.iterrows():\n",
        "                 if row['SEGMENTC30'].startswith('~'):\n",
        "                   cell_above = df.at[x - 1, 'SEGMENTC30']\n",
        "                   cell_above = cell_above.strip()\n",
        "                   last_char = cell_above[-2]\n",
        "                   df.at[x, 'SEGMENTC30'] = row['SEGMENTC30'].replace('~', '〈〈' + last_char + '〉〉') \n",
        "                    \n",
        "                    json_list = [] \n",
        "                    \n",
        "                    \n",
        "                    for reference_value, group in df.groupby('REFERENCEC8'): # Group the data in the dataframe by the \"REFERENCEC8\" column\n",
        "                    group_df = group.reset_index(drop=False) # Reset the index for the group\n",
        "                    json_dict = {} # Initialize the dictionary to store the contents of the JSON file\n",
        "                    json_dict['eClass'] = \"http://btsCorpusModel/1.0#//BTSSenctence\" \n",
        "                    json_dict['_id'] = 'FUNK-' + file_name_we + '-' + sheet_name + '-' + str(reference_value)\n",
        "                    json_dict['state'] = 'active'\n",
        "                    json_dict['sentenceItems'] = []\n",
        "                    json_dict['sentenceItems'].append({'eClass': \"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                                       '_id': 'FUNK-' + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-PARA-01\",\n",
        "                                                       'type': 'para',\n",
        "                                                       'name': str(reference_value)[-4:-2] + '-' + str(reference_value)[-2:], \n",
        "                                                       'state': 'active',})\n",
        "#need to check here                    \n",
        "                    counter = 1\n",
        "                    def add_sentence_item(row): # takes a row from the dataframe and adds a new sentence item to the json_dict\n",
        "                    global counter\n",
        "                    json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(counter),\n",
        "                                \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                 \"flexCode\": str(row[\"SEGMENTC30\"])})\n",
        "                    if str(row[\"SEGMENTC30\"]).endswith(\"·\"):\n",
        "                        json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(counter),\n",
        "                                \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                 \"flexCode\": str(row[\"SEGMENTC30\"][:-1])})\n",
        "                        json_dict['sentenceItems'].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                            \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + str(row[\"NO_LIGNEN60\"])+ \"-\" + str(counter)+ \"-INTP-01\",\n",
        "                                            \"type\": \"MiddleDot\",\n",
        "                                            \"state\": \"active\",\n",
        "                                            \"wChar\":\"·\"})    \n",
        "                        \n",
        "                    counter += 1\n",
        "                    \n",
        "                group_df.apply(add_sentence_item, axis=1) # Apply the add_sentence_item function to each row in the dataframe, called once per row(axis=1)\n",
        "        \n",
        "                \n",
        "                json_list.append(json_dict) # adds current json_dict to the json_list\n",
        "                file_path = os.path.join(path, file_name_we + '_' + sheet_name + '.json') # creating file path and name\n",
        "                with open(file_path, 'w', encoding='utf-8') as f: # opening the file with UTF-8 encoding\n",
        "                    json.dump(json_list, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "gkPgBMmN-XAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wht-h3CEHBLf",
        "outputId": "05c83d7d-bece-4433-fb0b-df915925a48a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d6d11452c631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# eckige Klammern, Kommata zwischen Sätze und Zeichensetzung, spitze Klammern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m# Loop through each file in the list of files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'"
          ]
        }
      ],
      "source": [
        "# 1. eckige Klammern um alle Sätze (1 Sheet) √\n",
        "# 2. Kommata zwischen einzelnen Sätzen in der JSON √\n",
        "# 3. Zeichensetzungsblock Middle-Dot Ergänzung √\n",
        "# 4. spitze Klammern um die Tildengeschichte √\n",
        "# 5. Loop reparieren √\n",
        "# 6. index bei 1 anfangen lassen √\n",
        "\n",
        "# Team: Thordis, Mehmet \n",
        "\n",
        "# Praxisprojekt / Python-Coding\n",
        "\n",
        "#def main():\n",
        "#  loop()\n",
        "#  json_dict()\n",
        "#  output()\n",
        "\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "# eckige Klammern, Kommata zwischen Sätze und Zeichensetzung, spitze Klammern\n",
        "path = 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for file in files:# Loop through each file in the list of files\n",
        "    if file.endswith('.xlsx'): # Check if the file ends with .xlsx\n",
        "        xlsx = pd.ExcelFile(path + file) # Read in the excel file using pandas\n",
        "        file_name_we, file_extension = os.path.splitext(file) # Split the file name and extension\n",
        "        for sheet in xlsx.sheet_names:# Loop through each sheet in the excel file\n",
        "            df = xlsx.parse(sheet)# Read in the data from the current sheet\n",
        "            sheet_name = sheet# Store the sheet name\n",
        "            df = df.rename(columns=lambda x: x.replace(',',''))# Rename the columns in the dataframe to remove any commas\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace(\"#\", \"-\")\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('^', 'ø', regex=False)\n",
        "            \n",
        "             for x, row in df.iterrows():\n",
        "                if row['SEGMENTC30'].startswith('~'):\n",
        "                    cell_above = df.at[x - 1, 'SEGMENTC30']\n",
        "                    cell_above = cell_above.strip()\n",
        "                    last_char = cell_above[-2]\n",
        "                    df.at[x, 'SEGMENTC30'] = row['SEGMENTC30'].replace(\"~\", '〈〈' + last_char + '〉〉') \n",
        "                    \n",
        "              \n",
        "            for reference_value, group in df.groupby('REFERENCEC8'):  # Group the data in the dataframe by the \"REFERENCEC8\" column\n",
        "                group_df = group.reset_index(drop=True) # Reset the index for the group, drop=True argument specifies that old index should be not added as a column in the dataframe\n",
        "                json_dict = {} # Initialize the dictionary to store the contents of the JSON file\n",
        "                json_dict['eClass'] = \"http://btsCorpusModel/1.0#//BTSSenctence\" \n",
        "                json_dict[\"_id\"] = \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value)\n",
        "                json_dict[\"state\"] = \"active\"\n",
        "                json_dict[\"sentenceItems\"] = []\n",
        "                json_dict[\"sentenceItems\"].append({\"eClass\": \"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                  \"_id\": \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-PARA-01\",\n",
        "                                  \"type\": \"para\",\n",
        "                                  \"name\": str(reference_value)[-4:-2] + \"-\" + str(reference_value)[-2:], \n",
        "                                  \"state\": \"active\",})\n",
        "                \n",
        "                for index, row in df.iterrows():# Loop through each row in the dataframe\n",
        "                    json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                        \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(index),\n",
        "                                        \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                         \"flexCode\": str(row[\"SEGMENTC30\"])}) \n",
        "               # if row['SEGMENTC30'].endswith('·'):\n",
        "                #    json_dict['sentenceItems'].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                 #                           \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + str(row[\"NO_LIGNEN60\"])+ \"-\" + str(index)+ \"-INTP-01\",\n",
        "                  #                          \"type\": \"MiddleDot\",\n",
        "                   #                         \"state\": \"active\",\n",
        "                    #                        \"wChar\":\"·\"}) \n",
        "                    \n",
        "                    \n",
        "            file_path = os.path.join(path, 'df' + '_' + '_' + sheet_name + '.json') # Creating file path and name\n",
        "            with open(file_path, 'w', encoding='utf-8') as f: # Opening the file with UTF-8 encoding\n",
        "                json.dump(json_dict, f, indent=1, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# if and else implementation\n",
        "\n",
        "path = 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for file in files:# Loop through each file in the list of files\n",
        "    if file.endswith('.xlsx'): # Check if the file ends with .xlsx\n",
        "        xlsx = pd.ExcelFile(path + file) # Read in the excel file using pandas\n",
        "        file_name_we, file_extension = os.path.splitext(file) # Split the file name and extension\n",
        "        for sheet in xlsx.sheet_names:# Loop through each sheet in the excel file\n",
        "            df = xlsx.parse(sheet)# Read in the data from the current sheet\n",
        "            sheet_name = sheet# Store the sheet name\n",
        "            df = df.rename(columns=lambda x: x.replace(',',''))# Rename the columns in the dataframe to remove any commas\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace(\"#\", \"-\")\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('^', 'ø', regex=False)\n",
        "            \n",
        "            for x, row in df.iterrows():\n",
        "                if row['SEGMENTC30'].startswith('~'):\n",
        "                    cell_above = df.at[x - 1, 'SEGMENTC30']\n",
        "                    last_char = cell_above[-2]\n",
        "                    df.at[x, 'SEGMENTC30'] = row['SEGMENTC30'].replace(\"~\", last_char)\n",
        "              \n",
        "            for reference_value, group in df.groupby('REFERENCEC8'):  # Group the data in the dataframe by the \"REFERENCEC8\" column\n",
        "                group_df = group.reset_index(drop=True) # Reset the index for the group, drop=True argument specifies that old index should be not added as a column in the dataframe\n",
        "                if reference_value == 'REFERENCEC8':\n",
        "                    json_list = []\n",
        "                    Satz_dict = {} # Initialize the dictionary to store the contents of the JSON file\n",
        "                    Satz_dict['eClass'] = \"http://btsCorpusModel/1.0#//BTSSenctence\" \n",
        "                    Satz_dict[\"_id\"] = \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value)\n",
        "                    Satz_dict[\"state\"] = \"active\"\n",
        "                    Satz_dict[\"sentenceItems\"] = []\n",
        "                    Satz_dict[\"sentenceItems\"].append({\"eClass\": \"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                      \"_id\": \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-PARA-01\",\n",
        "                                      \"type\": \"para\",\n",
        "                                      \"name\": str(reference_value)[-4:-2] + \"-\" + str(reference_value)[-2:], \n",
        "                                      \"state\": \"active\",})\n",
        "\n",
        "                current_reference = group_df.iloc[0]['REFERENCEC8'] # Store the current reference value\n",
        "                for index, row in group_df.iterrows(): # Loop through each row in the dataframe for the current reference value\n",
        "                    if row['REFERENCEC8'] != current_reference: # If the reference value changes\n",
        "                        break \n",
        "                    else: \n",
        "                        Satz_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(index),\n",
        "                                \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                 \"flexCode\": str(row[\"SEGMENTC30\"])})\n",
        "                    \n",
        "\n",
        "               # if row['SEGMENTC30'].endswith('·'):\n",
        "                #    json_dict['sentenceItems'].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                 #                           \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + str(row[\"NO_LIGNEN60\"])+ \"-\" + str(index)+ \"-INTP-01\",\n",
        "                  #                          \"type\": \"MiddleDot\",\n",
        "                   #                         \"state\": \"active\",\n",
        "                    #                        \"wChar\":\"·\"}) \n",
        "                    \n",
        "                    \n",
        "            file_path = os.path.join(path, 'df' + '_' + '_' + sheet_name + '.json') # Creating file path and name\n",
        "            with open(file_path, 'w', encoding='utf-8') as f: # Opening the file with UTF-8 encoding\n",
        "                json.dump(json_dict, f, indent=1, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "l6DUH43oO9bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Zielmockup\n",
        "\n",
        "[\n",
        "{\n",
        "\"eClass\":\"http://btsCorpusModel/1.0#//BTSSenctence\", \n",
        "\"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921\",\n",
        "\"state\":\"active\",\n",
        "\"sentenceItems\": [\n",
        "    {\n",
        "   \t \"eClass\": \"http://btsCorpusModel/1.0#//BTSMarker\",\n",
        "   \t \"_id\": \"FUNK-SAH-NEWT_1821JOHN-10401921-PARA-01\",\n",
        "   \t \"type\": \"para\",\n",
        "   \t \"name\": \"19,21\",\n",
        "   \t \"state\": \"active\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-1\",\n",
        "   \t \"lKey\":\"195-13\",\n",
        "   \t \"flexCode\":\"13\",\n",
        "   \t \"wChar\":\"ⲛⲉⲩ-\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-2\",\n",
        "   \t \"lKey\":\"858-5\",\n",
        "   \t \"flexCode\":\"5\",\n",
        "   \t \"wChar\":\"ϫⲱ\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-3\",\n",
        "   \t \"lKey\":\"462-6\",\n",
        "   \t \"flexCode\":\"6\",\n",
        "   \t \"wChar\":\"ϭⲉ\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-19\",\n",
        "   \t \"lKey\":\"4-8\",\n",
        "   \t \"flexCode\":\"8\",\n",
        "   \t \"wChar\":\"ⲛ̄-\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-20\",\n",
        "   \t \"lKey\":\"6-11\",\n",
        "   \t \"flexCode\":\"11\",\n",
        "   \t \"wChar\":\"〈〈ⲛ〉〉-\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-21\",\n",
        "   \t \"lKey\":\"7977-33\",\n",
        "   \t \"flexCode\":\"33\",\n",
        "   \t \"wChar\":\"ⲓ̈ⲟⲩⲇⲁⲓ̈\"\n",
        "    },\n",
        "    {\n",
        "   \t \"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\",\n",
        "   \t \"_id\":\"FUNK-SAH-NEWT_1821JOHN-10401921-109-21-INTP-01\",\n",
        "   \t \"type\": \"MiddleDot\",\n",
        "   \t \"state\": \"active\",\n",
        "   \t \"wChar\":\"·\"\n",
        "    }\n",
        "]\n",
        "}\n",
        ",\n",
        "]"
      ],
      "metadata": {
        "id": "S8j1m8wrbwog"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}