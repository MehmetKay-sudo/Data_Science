{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehmetKay-sudo/Data_Science/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc3xsBphQNJJ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "path = 'C:\\\\Users\\\\anton\\\\Jupyter\\\\coptic-project\\\\Auszug\\\\'\n",
        "files = os.listdir(path)\n",
        "\n",
        "for file in files:# Loop through each file in the list of files\n",
        "    if file.endswith('.xlsx'): # Check if the file ends with .xlsx\n",
        "        xlsx = pd.ExcelFile(path + file) # Read in the excel file using pandas\n",
        "        file_name_we, file_extension = os.path.splitext(file) # Split the file name and extension\n",
        "        for sheet in xlsx.sheet_names:# Loop through each sheet in the excel file\n",
        "            df = xlsx.parse(sheet)# Read in the data from the current sheet\n",
        "            sheet_name = sheet# Store the sheet name\n",
        "            df = df.rename(columns=lambda x: x.replace(',',''))# Rename the columns in the dataframe to remove any commas\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace(\"#\", \"-\")\n",
        "            df['SEGMENTC30'] = df['SEGMENTC30'].str.replace('^', 'ø', regex=False)\n",
        "            \n",
        "            for x, row in df.iterrows():\n",
        "                if row['SEGMENTC30'].startswith('~'):\n",
        "                    cell_above = df.at[x - 1, 'SEGMENTC30']\n",
        "                    last_char = cell_above[-1]\n",
        "                    if last_char == '#':\n",
        "                        cell_above = cell_above[:-1]\n",
        "                        last_char = cell_above[-1]\n",
        "                    df.at[x, 'SEGMENTC30'] = '~' + last_char ##spitze Klammern\n",
        "              \n",
        "            for reference_value, group in df.groupby('REFERENCEC8'):  # Group the data in the dataframe by the \"REFERENCEC8\" column\n",
        "                group_df = group.reset_index(drop=True) # Reset the index for the group, drop=True argument specifies that old index should be not added as a column in the dataframe\n",
        "                json_dict = {} # Initialize the dictionary to store the contents of the JSON file\n",
        "                json_dict['eClass'] = \"http://btsCorpusModel/1.0#//BTSSenctence\" \n",
        "                json_dict[\"_id\"] = \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value)\n",
        "                json_dict[\"state\"] = \"active\"\n",
        "                json_dict[\"sentenceItems\"] = []\n",
        "                json_dict[\"sentenceItems\"].append({\"eClass\": \"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                                  \"_id\": \"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-PARA-01\",\n",
        "                                  \"type\": \"para\",\n",
        "                                  \"name\": str(reference_value)[-4:-2] + \"-\" + str(reference_value)[-2:], \n",
        "                                  \"state\": \"active\",})\n",
        "                \n",
        "                for index, row in df.iterrows():# Loop through each row in the dataframe\n",
        "                    json_dict[\"sentenceItems\"].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSWord\", \n",
        "                                        \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + \"-\" + str(row[\"NO_LIGNEN60\"]) + \"-\" + str(index),\n",
        "                                        \"lKey\": str(row[\"NO_LEMMEN70\"]) + \"-\" + str(row[\"CD_GRAMMN20\"]),\n",
        "                                         \"flexCode\": str(row[\"SEGMENTC30\"])}) \n",
        "               # if row['SEGMENTC30'].endswith('·'):\n",
        "                #    json_dict['sentenceItems'].append({\"eClass\":\"http://btsCorpusModel/1.0#//BTSMarker\", \n",
        "                 #                           \"_id\":\"FUNK-\" + file_name_we + \"-\" + sheet_name + \"-\" + str(reference_value) + str(row[\"NO_LIGNEN60\"])+ \"-\" + str(index)+ \"-INTP-01\",\n",
        "                  #                          \"type\": \"MiddleDot\",\n",
        "                   #                         \"state\": \"active\",\n",
        "                    #                        \"wChar\":\"·\"}) \n",
        "                    \n",
        "                    \n",
        "            file_path = os.path.join(path, 'df' + '_' + '_' + sheet_name + '.json') # Creating file path and name\n",
        "            with open(file_path, 'w', encoding='utf-8') as f: # Opening the file with UTF-8 encoding\n",
        "                json.dump(json_dict, f, indent=1, ensure_ascii=False)"
      ]
    }
  ]
}